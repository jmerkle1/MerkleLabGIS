require(terra)
require(sf)
require(httr)
require(jsonlite)
require(tidyverse)
points <- data.frame(id = c(1, 2), x = c(-108.36312, -109.36312),  y = c(45.54731, 45.54731)) %>%
sf::st_as_sf(coords = c("x", "y"), crs = 4326)
myDaymetMetrics<- httr::POST(
"https://devise.uwyo.edu/umbraco/api/daymetapi/GetDerivedAnnualMetricsList",
content_type_json()
) %>%
content()
myDaymetMetrics <- do.call(rbind.data.frame, myDaymetMetrics)
dat<- httr::POST(
"https://devise.uwyo.edu/umbraco/api/Daymetapi/GetDerivedAnnualData",
httr::content_type_json(),
body = jsonlite::toJSON(
list(StartDate = jsonlite::unbox("2005-01-01"),
EndDate = jsonlite::unbox("2008-01-01"),
Metrics = myDaymetMetrics$metric[1]),
auto_unbox = FALSE
)
) %>%
content()
dat <- do.call(rbind.data.frame, dat)
outDir <- "~/Desktop/Daymet"
# loop through each file and download
for(j in 1:nrow(dat)){
try(utils::download.file(url = dat$url[j], destfile = paste0(outDir, "/", dat$filename[j]), quiet = TRUE, mode = "wb"), silent = TRUE)
}
outDir <- "C:/Users/cowboy/Desktop/Daymet"
# loop through each file and download
for(j in 1:nrow(dat)){
try(utils::download.file(url = dat$url[j], destfile = paste0(outDir, "/", dat$filename[j]), quiet = TRUE, mode = "wb"), silent = TRUE)
}
# Get the newly downloaded files
rfiles<- dir(outDir, pattern = ".tif$", full.names = TRUE)
# Stack the rasters into one
rs<- terra::rast(rfiles)
# Change the names of the layers to something more meaningful
names(rs) <- str_split(dat$filename, "\\.", simplify = TRUE)[,1]
pts<- vect(as(points %>% st_transform(crs = 5072), "Spatial"))
## Extract some sort of data here
myMaxPrcpData<- terra::extract(rs, pts, ID = FALSE)
View(myMaxPrcpData)
# Use this to manipulate data into an easier to read format and plot the trends
dfPts<- cbind(points, myMaxPrcpData) %>%
st_drop_geometry() %>%
pivot_longer(cols = 2:ncol(.), names_to = "Raster", values_to = "Value") %>%
separate(Raster, into = c("Source", "Parameter", "SampYear"), sep = "_")
# plot data
dfPts %>%
ggplot(aes(x = SampYear, y = Value, group = as.factor(id), color = as.factor(id))) +
geom_line()
View(myMaxPrcpData)
ExtractDAYMET <- function(point_data,
start_date = "2005-01-01",
end_date = "2010-01-01",
metric_name = NULL) {
# Load necessary libraries
require(terra)
require(sf)
require(httr)
require(jsonlite)
require(tidyverse)
if(!inherits(point_data, "sf")) {
stop("point_data must be an sf object")
}
# Obtain the list of all available metrics
myDaymetMetrics <- httr::POST("https://devise.uwyo.edu/umbraco/api/daymetapi/GetDerivedAnnualMetricsList", content_type_json()) %>% content()
myDaymetMetrics <- do.call(rbind.data.frame, myDaymetMetrics)
# Select metric
if(is.null(metric_name)) {
metric <- myDaymetMetrics$metric[1]
} else {
metric <- metric_name
}
# Get the data
dat <- httr::POST("https://devise.uwyo.edu/umbraco/api/Daymetapi/GetDerivedAnnualData",
httr::content_type_json(),
body = jsonlite::toJSON(list(StartDate = jsonlite::unbox(start_date),
EndDate = jsonlite::unbox(end_date),
Metrics = metric),
auto_unbox = FALSE)
) %>% content()
dat <- do.call(rbind.data.frame, dat)
# Read rasters directly from URL
rasters <- lapply(dat$url, function(url) terra::rast(url))
# Combine the rasters
rs <- do.call(c, rasters)
names(rs) <- str_split(dat$filename, "\\.", simplify = TRUE)[,1]
pts <- vect(as(points %>% st_transform(crs = 5072), "Spatial"))
# Extract data
myMaxPrcpData <- terra::extract(rs, pts, ID = FALSE)
df <- as.data.frame(myMaxPrcpData)
names(df) <- names(rs)
result <- cbind(point_data, df)
return(result)
}
View(myDaymetMetrics)
results<- ExtractDAYMET(points, metric_name = "Maxprcp")
View(results)
View(myMaxPrcpData)
library(MerkleLabGIS)
install.packages(jmerkle1/MerkleLabGIS)
devtools::install_github("jmerkle1/MerkleLabGIS")
